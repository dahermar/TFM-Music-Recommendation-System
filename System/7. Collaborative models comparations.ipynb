{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67221f5a",
   "metadata": {},
   "source": [
    "# 7. Collaborative models comparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1ed38",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e81bfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "print(os.environ.get(\"OPENBLAS_NUM_THREADS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a25959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danih\\anaconda3\\envs\\MasterIA\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix, csc_matrix, lil_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.evaluation import leave_k_out_split\n",
    "RANDOM_STATE = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc525f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('data/User Listening History_modified.csv')\n",
    "df_music = pd.read_csv('data/Million Song Dataset kaggle/Music Info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58987a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_music_info = df_music[['track_id', 'name', 'artist', 'energy', 'duration_ms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac7fdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464573"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = df_users['user_id'].nunique()\n",
    "num_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e06e4",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc340fb",
   "metadata": {},
   "source": [
    "### Item Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19bb5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemBasedRecommender:\n",
    "    def __init__(self, interaction_matrix, item_similarity, track_uniques, df_music_info):\n",
    "        self.interaction_matrix = interaction_matrix\n",
    "        self.item_similarity = item_similarity\n",
    "        self.track_uniques = track_uniques\n",
    "        self.df_music_info = df_music_info\n",
    "        self.user_index = None\n",
    "        self.recommendations = None # List of tuples (track_id, energy, similarity, has been recommended)\n",
    "\n",
    "    def make_recommendations(self, user_index, n=100):\n",
    "        self.user_index = user_index\n",
    "        user_ratings = self.interaction_matrix[self.user_index]\n",
    "        interacted = user_ratings.nonzero()[1]\n",
    "        similarities = self.item_similarity.dot(user_ratings.T).toarray().ravel()\n",
    "        similarities[interacted] = -np.inf\n",
    "        top_n_index = np.argpartition(similarities, -n)[-n:]\n",
    "        top_n_index = top_n_index[np.argsort(similarities[top_n_index])[::-1]]\n",
    "\n",
    "        # for index in top_n_index:\n",
    "        #     print(f\"Track ID: {self.track_uniques[index]}, Similarity: {similarities[index]}\")\n",
    "\n",
    "        track_ids = self.track_uniques[top_n_index].tolist()\n",
    "        df_filtered = self.df_music_info.set_index('track_id').loc[track_ids][['energy']].reset_index()\n",
    "        index_to_similarity = {idx: similarities[idx] for idx in top_n_index}\n",
    "\n",
    "        self.recommendations = [(track_id, energy, index_to_similarity[self.track_uniques.tolist().index(track_id)], False) for track_id, energy in df_filtered.itertuples(index=False, name=None)]\n",
    "\n",
    "    \n",
    "    def recommend_song(self, energy, energy_margin=0.05):\n",
    "        if self.recommendations is None:\n",
    "            raise ValueError(\"No recommendations available. Please call make_recommendations first.\")\n",
    "        \n",
    "        closest_track_index = None\n",
    "        distance_to_energy = float('inf')\n",
    "\n",
    "        for i, (track_id, track_energy, similarity, has_been_recommended) in enumerate(self.recommendations):\n",
    "            distance = abs(track_energy - energy)\n",
    "\n",
    "            if not has_been_recommended and distance <= energy_margin:\n",
    "                self.recommendations[i] = (track_id, track_energy, similarity, True)\n",
    "                return (track_id, track_energy)\n",
    "            \n",
    "            if not has_been_recommended and distance < distance_to_energy:\n",
    "                closest_track_index = i\n",
    "                distance_to_energy = distance\n",
    "        \n",
    "        if closest_track_index is not None:\n",
    "            track_id, track_energy, _, _= self.recommendations[closest_track_index]\n",
    "            self.recommendations[closest_track_index] = (track_id, track_energy, similarity, True)\n",
    "            return (track_id, track_energy)\n",
    "\n",
    "        raise ValueError(\"All recommendations have already been recommended\")\n",
    "\n",
    "\n",
    "    def get_recommendations(self):\n",
    "        if self.recommendations is None:\n",
    "            raise ValueError(\"No recommendations available. Please call make_recommendations first.\")\n",
    "        return self.recommendations\n",
    "\n",
    "\n",
    "    def get_recommendations_ids(self):\n",
    "        if self.recommendations is None:\n",
    "            raise ValueError(\"No recommendations available. Please call make_recommendations first.\")\n",
    "        return [track_id for track_id, _, _, _ in self.recommendations]\n",
    "    \n",
    "    def get_recommendations_info(self):\n",
    "        track_ids_ordered = [track_id for track_id, _, _, _ in self.recommendations]\n",
    "        df_ordered = self.df_music_info.set_index('track_id').loc[track_ids_ordered].reset_index()\n",
    "        return df_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217243a4",
   "metadata": {},
   "source": [
    "### User based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789d5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserBasedRecommender:\n",
    "    def __init__(self, interaction_matrix, track_uniques, df_music_info, num_neighbors=10):\n",
    "        self.interaction_matrix = interaction_matrix\n",
    "        self.knn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=num_neighbors + 1, n_jobs=-1) # num_neighbors+1 because the user itself is included in the neighbors and we will ignore it\n",
    "        self.knn_model.fit(interaction_matrix)\n",
    "        self.track_uniques = track_uniques\n",
    "        self.df_music_info = df_music_info\n",
    "        self.user_index = None\n",
    "        self.recommendations = None # List of tuples (track_id, energy, has been recommended)\n",
    "\n",
    "    def make_recommendations(self, user_index, n=5):\n",
    "        self.user_index = user_index\n",
    "\n",
    "        _, neighbors_indices = self.knn_model.kneighbors(self.interaction_matrix[user_index])\n",
    "\n",
    "        neighbors_indices = neighbors_indices[:, 1:]  # Exclude the first index which is the user itself\n",
    "\n",
    "        neighbors_interaction_matrix = self.interaction_matrix[neighbors_indices.flatten()]\n",
    "\n",
    "        neighbors_mean_ratings = neighbors_interaction_matrix.mean(axis=0).A1 # Converts to 1D array\n",
    "\n",
    "        user_ratings = self.interaction_matrix[user_index]\n",
    "        interacted = user_ratings.nonzero()[1]\n",
    "        neighbors_mean_ratings[interacted] = -np.inf #Asign -np.inf to already listened songs by the user\n",
    "\n",
    "        top_n_index = np.argpartition(neighbors_mean_ratings, -n)[-n:]\n",
    "        top_n_index = top_n_index[np.argsort(neighbors_mean_ratings[top_n_index])[::-1]]\n",
    "\n",
    "        # for index in top_n_index:\n",
    "        #     print(f\"Track ID: {self.track_uniques[index]}, Mean Rating: {neighbors_mean_ratings[index]}\")\n",
    "        \n",
    "        track_ids = self.track_uniques[top_n_index].tolist()\n",
    "\n",
    "        df_filtered = self.df_music_info.set_index('track_id').loc[track_ids][['energy']].reset_index()\n",
    "\n",
    "        # print(df_filtered)\n",
    "\n",
    "        self.recommendations = [(track_id, energy, False) for track_id, energy in df_filtered.itertuples(index=False, name=None)]\n",
    "\n",
    "    \n",
    "    def recommend_song(self, energy, energy_margin=0.05):\n",
    "        if self.recommendations is None:\n",
    "            raise ValueError(\"No recommendations available. Please call make_recommendations first.\")\n",
    "        \n",
    "        closest_track_index = None\n",
    "        distance_to_energy = float('inf')\n",
    "\n",
    "        for i, (track_id, track_energy, has_been_recommended) in enumerate(self.recommendations):\n",
    "            distance = abs(track_energy - energy)\n",
    "\n",
    "            if not has_been_recommended and distance <= energy_margin:\n",
    "                self.recommendations[i] = (track_id, track_energy, True)\n",
    "                return (track_id, track_energy)\n",
    "            \n",
    "            if not has_been_recommended and distance < distance_to_energy:\n",
    "                closest_track_index = i\n",
    "                distance_to_energy = distance\n",
    "        \n",
    "        if closest_track_index is not None:\n",
    "            track_id, track_energy, _ = self.recommendations[closest_track_index]\n",
    "            self.recommendations[closest_track_index] = (track_id, track_energy, True)\n",
    "            return (track_id, track_energy)\n",
    "\n",
    "        raise ValueError(\"All recommendations have already been recommended\")\n",
    "\n",
    "\n",
    "    def get_recommendations(self):\n",
    "        if self.recommendations is None:\n",
    "            raise ValueError(\"No recommendations available. Please call make_recommendations first.\")\n",
    "        return self.recommendations\n",
    "\n",
    "\n",
    "    def get_recommendations_ids(self):\n",
    "        if self.recommendations is None:\n",
    "            raise ValueError(\"No recommendations available. Please call make_recommendations first.\")\n",
    "        return [track_id for track_id, _, _ in self.recommendations]\n",
    "    \n",
    "    \n",
    "    def get_recommendations_info(self):\n",
    "        if self.recommendations is None:\n",
    "            raise ValueError(\"No recommendations available. Please call make_recommendations first.\")\n",
    "        track_ids_ordered = [track_id for track_id, _, _ in self.recommendations]\n",
    "        df_ordered = self.df_music_info.set_index('track_id').loc[track_ids_ordered].reset_index()\n",
    "        return df_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931664f7",
   "metadata": {},
   "source": [
    "### Matrix Factorization: Alternating Least Squares (ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e7f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSRecommender:\n",
    "    def __init__(self, interaction_matrix, track_uniques, df_music_info, als_model=None):\n",
    "        self.interaction_matrix = interaction_matrix\n",
    "        self.track_uniques = track_uniques\n",
    "        self.df_music_info = df_music_info\n",
    "\n",
    "        if als_model is None:\n",
    "            self.als_model = AlternatingLeastSquares(factors=50, regularization=0.1, iterations=20, num_threads=0, random_state=RANDOM_STATE)\n",
    "            self.als_model.fit(self.interaction_matrix)\n",
    "        else:\n",
    "            self.als_model = als_model\n",
    "\n",
    "        self.user_index = None\n",
    "        self.recommendations = None # List of tuples (track_id, energy, similarity, has been recommended)\n",
    "\n",
    "    def make_recommendations(self, user_index, n=100):\n",
    "        self.user_index = user_index\n",
    "\n",
    "        user_items = self.interaction_matrix.tocsr()[user_index]\n",
    "\n",
    "\n",
    "        top_n_recommendations_indexes, top_n_recommendations_scores = self.als_model.recommend(user_index, user_items, N=n, filter_already_liked_items=True)\n",
    "\n",
    "        # for i in range(len(top_n_recommendations_indexes)):\n",
    "        #     print(f\"Track ID: {self.track_uniques[top_n_recommendations_indexes[i]]}, Similarity: {top_n_recommendations_scores[i]}\")\n",
    "\n",
    "\n",
    "        track_ids = self.track_uniques[top_n_recommendations_indexes].tolist()\n",
    "        \n",
    "        df_filtered = self.df_music_info.set_index('track_id').loc[track_ids][['energy']].reset_index()\n",
    "\n",
    "        self.recommendations = [(track_id, energy, similarity, False) for (track_id, energy), similarity in zip(df_filtered.itertuples(index=False, name=None), top_n_recommendations_scores)]\n",
    "        return self.recommendations\n",
    "\n",
    "    \n",
    "    def recommend_song(self, energy, energy_margin=0.05):\n",
    "        if self.recommendations is None:\n",
    "            raise ValueError(\"No recommendations available. Please call make_recommendations first.\")\n",
    "        \n",
    "        closest_track_index = None\n",
    "        distance_to_energy = float('inf')\n",
    "\n",
    "        for i, (track_id, track_energy, similarity, has_been_recommended) in enumerate(self.recommendations):\n",
    "            distance = abs(track_energy - energy)\n",
    "\n",
    "            if not has_been_recommended and distance <= energy_margin:\n",
    "                self.recommendations[i] = (track_id, track_energy, similarity, True)\n",
    "                return (track_id, track_energy)\n",
    "            \n",
    "            if not has_been_recommended and distance < distance_to_energy:\n",
    "                closest_track_index = i\n",
    "                distance_to_energy = distance\n",
    "        \n",
    "        if closest_track_index is not None:\n",
    "            track_id, track_energy, _, _= self.recommendations[closest_track_index]\n",
    "            self.recommendations[closest_track_index] = (track_id, track_energy, similarity, True)\n",
    "            return (track_id, track_energy)\n",
    "\n",
    "        raise ValueError(\"All recommendations have already been recommended\")\n",
    "\n",
    "\n",
    "    def get_recommendations(self):\n",
    "        if self.recommendations is None:\n",
    "            raise ValueError(\"No recommendations available. Please call make_recommendations first.\")\n",
    "        return self.recommendations\n",
    "\n",
    "\n",
    "    def get_recommendations_ids(self):\n",
    "        if self.recommendations is None:\n",
    "            raise ValueError(\"No recommendations available. Please call make_recommendations first.\")\n",
    "        return [track_id for track_id, _, _, _ in self.recommendations]\n",
    "    \n",
    "    def get_recommendations_info(self):\n",
    "        track_ids = [track_id for track_id, _, _, _ in self.recommendations]\n",
    "        df_ordered = self.df_music_info.set_index('track_id').loc[track_ids].reset_index()\n",
    "        return df_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df9909",
   "metadata": {},
   "source": [
    "## Interaction Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e54cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_agg = df_users.groupby('user_id')['playcount'].agg(\n",
    "    #total_playcount='sum',\n",
    "    max_playcount='max'\n",
    ").reset_index()\n",
    "df_users_agg = df_users_agg.rename(columns={'playcount': 'max_playcount'})\n",
    "\n",
    "df_users_rating = df_users.merge(df_users_agg, on='user_id')\n",
    "df_users_rating['rating'] = df_users_rating['playcount'] / df_users_rating['max_playcount']\n",
    "\n",
    "user_codes, user_uniques = pd.factorize(df_users['user_id'])\n",
    "track_codes, track_uniques = pd.factorize(df_users['track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0bdb233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import bm25_weight\n",
    "\n",
    "interaction_matrix_user_based = csr_matrix((np.ones(len(df_users)), (user_codes, track_codes)),shape=(len(user_uniques), len(track_uniques)))\n",
    "interaction_matrix_item_based = csc_matrix((np.ones(len(df_users)), (user_codes, track_codes)),shape=(len(user_uniques), len(track_uniques)))\n",
    "#interaction_matrix_item_based = csc_matrix((df_users_rating['rating'], (user_codes, track_codes)),shape=(len(user_uniques), len(track_uniques)))\n",
    "\n",
    "interaction_matrix_user_item_original = csr_matrix(\n",
    "    (df_users_rating['playcount'], (user_codes, track_codes)),\n",
    "    shape=(len(user_uniques), len(track_uniques))\n",
    ")\n",
    "\n",
    "interaction_matrix_als = bm25_weight(interaction_matrix_user_item_original, K1=1.2, B=0.75).tocsr() #We use K1 and B parameters as default values (K1=100, B=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218b4eb",
   "metadata": {},
   "source": [
    "## Model Comparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c0b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(real, predicted, k=20):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in real and p not in predicted[:i]:  # avoid duplicate hits\n",
    "            hits += 1.0\n",
    "            score += hits / (i + 1.0)\n",
    "\n",
    "    return score / min(len(real), k) if real else 0.0\n",
    "\n",
    "\n",
    "def mapk(actual_list, predicted_list, k=10):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual_list, predicted_list)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdaf2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(relevance_scores, k):\n",
    "    relevance_scores = np.asarray(relevance_scores, dtype=float)[:k]\n",
    "    if relevance_scores.size:\n",
    "        return np.sum(relevance_scores / np.log2(np.arange(2, relevance_scores.size + 2)))\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def ndcg(actual, predicted, k=10):\n",
    "    predicted = predicted[:k]\n",
    "    relevance_scores = [1 if p in actual else 0 for p in predicted]\n",
    "    ideal_scores = sorted(relevance_scores, reverse=True)\n",
    "\n",
    "    actual_dcg = dcg(relevance_scores, k)\n",
    "    ideal_dcg = dcg(ideal_scores, k)\n",
    "\n",
    "    return actual_dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
    "\n",
    "\n",
    "def mean_ndcg(actual_list, predicted_list, k=10):\n",
    "    return np.mean([ndcg(a, p, k) for a, p in zip(actual_list, predicted_list)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3a0c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_split_from_indices(matrix, test_users, test_items):\n",
    "    train_lil = matrix.tolil()\n",
    "    test_lil = lil_matrix(matrix.shape)\n",
    "\n",
    "   \n",
    "    for u, i in zip(test_users, test_items):\n",
    "        val = matrix[u, i]\n",
    "        train_lil[u, i] = 0\n",
    "        test_lil[u, i] = val\n",
    "\n",
    "    \n",
    "    train = train_lil.tocsr()\n",
    "    test = test_lil.tocsr()\n",
    "    return train, test\n",
    "\n",
    "def generate_3_splits(interaction_matrix_1, interaction_matrix_2, interaction_matrix_3, k=1, random_state=RANDOM_STATE):\n",
    "    train_matrix_1, test_matrix_1 = leave_k_out_split(interaction_matrix_1, K = k, random_state=random_state)\n",
    "    test_users, test_items = test_matrix_1.nonzero()\n",
    "    train_matrix_2, test_matrix_2 = build_split_from_indices(interaction_matrix_2, test_users, test_items)\n",
    "    train_matrix_3, test_matrix_3 = build_split_from_indices(interaction_matrix_3, test_users, test_items)\n",
    "    return train_matrix_1, test_matrix_1, train_matrix_2, test_matrix_2, train_matrix_3, test_matrix_3\n",
    "\n",
    "def generate_2_splits_form_split(train_matrix_1, test_matrix_1, interaction_matrix_2, interaction_matrix_3, k=1, random_state=RANDOM_STATE):\n",
    "    test_users, test_items = test_matrix_1.nonzero()\n",
    "    train_matrix_2, test_matrix_2 = build_split_from_indices(interaction_matrix_2, test_users, test_items)\n",
    "    train_matrix_3, test_matrix_3 = build_split_from_indices(interaction_matrix_3, test_users, test_items)\n",
    "    return train_matrix_2, test_matrix_2, train_matrix_3, test_matrix_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18689e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_als, test_matrix_als, train_matrix_item_based, test_matrix_item_based, train_matrix_user_based, test_matrix_user_based = generate_3_splits(interaction_matrix_als, interaction_matrix_item_based, interaction_matrix_user_based, k=1, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56722b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('matrices/train_matrix_als_final_prueba2.pkl', 'wb') as f:\n",
    "    pickle.dump(train_matrix_als, f)\n",
    "\n",
    "with open('matrices/test_matrix_als_final_prueba2.pkl', 'wb') as f:\n",
    "    pickle.dump(test_matrix_als, f)\n",
    "\n",
    "with open('matrices/train_matrix_item_based_final_prueba2.pkl', 'wb') as f:\n",
    "    pickle.dump(train_matrix_item_based, f)\n",
    "\n",
    "with open('matrices/test_matrix_item_based_final_prueba2.pkl', 'wb') as f:\n",
    "    pickle.dump(test_matrix_item_based, f)\n",
    "\n",
    "with open('matrices/train_matrix_user_based_final_prueba2.pkl', 'wb') as f:\n",
    "    pickle.dump(train_matrix_user_based, f)\n",
    "\n",
    "with open('matrices/test_matrix_user_based_final_prueba2.pkl', 'wb') as f:\n",
    "    pickle.dump(test_matrix_user_based, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d16707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [14:07<00:00, 42.37s/it]\n"
     ]
    }
   ],
   "source": [
    "als_model = AlternatingLeastSquares(factors=600, regularization=1, iterations=20, alpha=9, num_threads=1, random_state=RANDOM_STATE)\n",
    "als_model.fit(train_matrix_als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6e60e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/als_comparation_600_1_9_prueba2.pkl', 'wb') as f:\n",
    "    pickle.dump(als_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "579a21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_similarity = cosine_similarity(train_matrix_item_based.T, dense_output=False)\n",
    "item_based_similarity = csc_matrix(item_based_similarity)\n",
    "\n",
    "\n",
    "item_based_recommender = ItemBasedRecommender(train_matrix_item_based, item_based_similarity, track_uniques, df_music_info)\n",
    "user_based_recommender = UserBasedRecommender(train_matrix_user_based, track_uniques, df_music_info, num_neighbors=160)\n",
    "als_recommender = ALSRecommender(train_matrix_als, track_uniques, df_music_info, als_model=als_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6df607dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(RANDOM_STATE)\n",
    "user_indices = rng.choice(train_matrix_als.shape[0], size=40000, replace=False) #  size=num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f61cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [1:40:22<00:00,  6.64it/s]\n"
     ]
    }
   ],
   "source": [
    "real_items = []\n",
    "predicted_items_item_based = []\n",
    "predicted_items_user_based = []\n",
    "predicted_items_als = []\n",
    "\n",
    "\n",
    "for user_index in tqdm(user_indices):\n",
    "    real_indexes = test_matrix_als[user_index].nonzero()[1]\n",
    "    real_items.append(set(track_uniques[real_indexes]))\n",
    "\n",
    "    item_based_recommender.make_recommendations(user_index, n=20)\n",
    "    predicted_items_item_based.append(item_based_recommender.get_recommendations_ids())\n",
    "\n",
    "    user_based_recommender.make_recommendations(user_index, n=20)\n",
    "    predicted_items_user_based.append(user_based_recommender.get_recommendations_ids())\n",
    "\n",
    "    als_recommender.make_recommendations(user_index, n=20)\n",
    "    predicted_items_als.append(als_recommender.get_recommendations_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e591b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapk_item_based = mapk(real_items, predicted_items_item_based, k=20)\n",
    "mapk_user_based = mapk(real_items, predicted_items_user_based, k=20)\n",
    "mapk_als = mapk(real_items, predicted_items_als, k=20)\n",
    "\n",
    "ndcg_item_based = mean_ndcg(real_items, predicted_items_item_based, k=20)\n",
    "ndcg_user_based = mean_ndcg(real_items, predicted_items_user_based, k=20)\n",
    "ndcg_als = mean_ndcg(real_items, predicted_items_als, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d17cf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAP@20</th>\n",
       "      <th>NDCG@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Item-Based</td>\n",
       "      <td>0.175067</td>\n",
       "      <td>0.219750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User-Based</td>\n",
       "      <td>0.171706</td>\n",
       "      <td>0.210334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALS</td>\n",
       "      <td>0.180535</td>\n",
       "      <td>0.228965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model    MAP@20   NDCG@20\n",
       "0  Item-Based  0.175067  0.219750\n",
       "1  User-Based  0.171706  0.210334\n",
       "2         ALS  0.180535  0.228965"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Item-Based', 'User-Based', 'ALS'],\n",
    "    'MAP@20': [mapk_item_based, mapk_user_based, mapk_als],\n",
    "    'NDCG@20': [ndcg_item_based, ndcg_user_based, ndcg_als]\n",
    "})\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
